---
title: 'COVID Scraping'
author: 'Jeffrey Brennan'
date: '5/22/2020'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(plyr)
library(data.table)
library(readxl)
library(dplyr)
```

# COUNTY LEVEL

## JHU

```{r}
JHU_cases = fread('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv')

JHU_deaths = fread('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv')
```

JHU Cleaning

```{r}
JHU_cases$Type = 'cases'
JHU_deaths$Type = 'deaths'

JHU_texas_deaths = subset(JHU_deaths, Province_State == 'Texas')
JHU_texas_cases = subset(JHU_cases, Province_State == 'Texas')
JHU_texas_df = rbind(JHU_texas_cases, JHU_texas_deaths[, -12])
write.csv(JHU_cases, 'original-sources/JHU.csv')

JHU_texas_df$Population = rep(JHU_texas_deaths$Population, times = 2)
```

```{r}
JHU_texas_df = JHU_texas_df[, -c(2:4, 8, 11)]
colnames(JHU_texas_df)[3:6] = c('County', 'State', 'Lat', 'Long')

# force as data frame to avoid type issue
JHU_texas_long = as.data.frame(reshape::melt(JHU_texas_df, id = c('UID', 'FIPS', 'County', 'State', 'Lat', 'Long', 'Type', 'Population')))
```

```{r}
colnames(JHU_texas_long)[9:10] = c('Date', 'Value')

# fix types
JHU_texas_long$Type = as.factor(JHU_texas_long$Type)

# fix dates
# JHU_texas_long$Date = gsub('X', '', JHU_texas_long$Date)
JHU_texas_long$Date = as.Date(as.character(JHU_texas_long$Date), format = '%m/%d/%y')
```

```{r}
JHU_texas_long$Deaths = (subset(JHU_texas_long, Type == 'deaths')[, 'Value'])
JHU_texas_long = subset(JHU_texas_long, Type == 'cases')
JHU_texas_long$Type = NULL
colnames(JHU_texas_long)[colnames(JHU_texas_long) == 'Value'] = 'Cases_Cumulative'
colnames(JHU_texas_long)[colnames(JHU_texas_long) == 'Deaths'] = 'Deaths_Cumulative'
```

```{r}
# add source col
JHU_texas_long$Source = 'JHU'
```


## NYT

```{r}
NYT_combined = fread('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv')
```

NYT Cleaning

```{r}
# filter texas only
NYT_texas = subset(NYT_combined, state == 'Texas')
write.csv(NYT_texas, 'original-sources/NYT.csv', row.names = F)

# convert dates to dates
NYT_texas$date = as.Date(NYT_texas$date)

# add source col
NYT_texas$Source = 'NYT'

# fix column names
colnames(NYT_texas) = c('Date', 'County', 'State', 'FIPS', 'Cases_Cumulative', 'Deaths_Cumulative', 'Source')
```

## USA Facts

```{r}
US_FACTS_cases = fread('https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_confirmed_usafacts.csv')
US_FACTS_deaths = fread('https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_deaths_usafacts.csv')
US_FACTS_pops = fread('https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_county_population_usafacts.csv')
```

 USA FACTS Cleaning
```{r}
US_FACTS_cases$Type = 'cases'
US_FACTS_deaths$Type = 'deaths'

US_FACTS_counts = rbind(US_FACTS_cases, US_FACTS_deaths)
US_FACTS_texas = subset(US_FACTS_counts, State == 'TX')
write.csv(US_FACTS_texas, 'original-sources/USA_FACTS.csv', row.names = F)

# # fix encoding issue with first col
colnames(US_FACTS_texas)[1] = 'FIPS'
colnames(US_FACTS_pops)[1] = 'FIPS'

# add pop
# US_FACTS_texas = merge(US_FACTS_texas, US_FACTS_pops[, 'population'], by = 'FIPS')
US_FACTS_texas = merge(US_FACTS_texas, US_FACTS_pops[, c('FIPS', 'population')], by = 'FIPS')
```

```{r}
# drop 'stateFIPS'
US_FACTS_texas$stateFIPS = NULL

# make long
# force as dataframe to avoid memory leak? freezing 2 blocks down
US_FACTS_texas_long = as.data.frame(reshape::melt(US_FACTS_texas, id = c('FIPS', 'County Name', 'State', 'Type', 'population')))
```

```{r}
# fix colnames
colnames(US_FACTS_texas_long) = c('FIPS', 'County', 'State', 'Type', 'Population', 'Date', 'Value')

# drop 'County' suffix
US_FACTS_texas_long$County = gsub(' County', '', US_FACTS_texas_long$County)

# fix dates
US_FACTS_texas_long$Date = as.Date(as.character(US_FACTS_texas_long$Date), format = '%m/%d/%y')
```

```{r}
# append deaths
# sort by Type
US_FACTS_texas_long = US_FACTS_texas_long[order(US_FACTS_texas_long$Type), ]

US_FACTS_texas_long$Deaths = (subset(US_FACTS_texas_long, Type == 'deaths')[, 'Value'])
US_FACTS_texas_long = subset(US_FACTS_texas_long, Type == 'cases')
US_FACTS_texas_long$Type = NULL
colnames(US_FACTS_texas_long)[colnames(US_FACTS_texas_long) == 'Value'] = 'Cases_Cumulative'
colnames(US_FACTS_texas_long)[colnames(US_FACTS_texas_long) == 'Deaths'] = 'Deaths_Cumulative'

```

```{r}
# convert county to factor
US_FACTS_texas_long$County = as.factor(US_FACTS_texas_long$County)
US_FACTS_texas_long$Source = 'USA Facts'
```

## Google mobility

Used fread for faster import - very large file

```{r}
mobility_data = fread('https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv')
```

```{r}
# filter mobility
mobility_texas = subset(mobility_data, sub_region_1 == 'Texas')

# drop cols
mobility_texas = mobility_texas[, -c(1,2)]
write.csv(mobility_texas, 'original-sources/GOOGLE.csv', row.names = F)

# fix colnames
# values represent percent change from baseline
colnames(mobility_texas) = c('State', 'County', 'Date', 'Retail_Recreation', 'Grocery_Pharmacy', 'Parks', 'Transit', 'Workplaces', 'Residential')

# Add name for blank county cells & drop 'county' suffix
mobility_texas$County = sub('^$', 'Unallocated', mobility_texas$County)
mobility_texas$County = gsub(' County', '', mobility_texas$County)

#fix types
mobility_texas$State = as.factor(mobility_texas$State)
mobility_texas$County = as.factor(mobility_texas$County)
mobility_texas$Date = as.Date(mobility_texas$Date)
```


## DSHS 

```{r}
# cases
case_url = 'http://dshs.texas.gov/coronavirus/TexasCOVID19DailyCountyCaseCountData.xlsx'
temp = tempfile()
download.file(case_url, temp, mode = 'wb') 
DSHS_cases_time = data.frame(readxl::read_excel(temp, sheet = 1))

# fix colnames
colnames(DSHS_cases_time) = DSHS_cases_time[2, ]
DSHS_cases_time = DSHS_cases_time[3:(nrow(DSHS_cases_time) - 11), ]
colnames(DSHS_cases_time)[1] = 'County'

# melt
DSHS_cases_long = reshape::melt(DSHS_cases_time, id = c('County', 'Population'))
                                
# set colnames
colnames(DSHS_cases_long) = c('County', 'Population', 'Date', 'Cases_Cumulative')

# fix dates
DSHS_cases_long$Date = as.Date(gsub('Cases\r|\r|\n', '', DSHS_cases_long$Date), format = '%m-%d')
```

```{r}
# deaths
death_url = 'https://dshs.texas.gov/coronavirus/TexasCOVID19DailyCountyFatalityCountData.xlsx'
temp = tempfile()
download.file(death_url, temp, mode = 'wb') 
DSHS_deaths_time = data.frame(readxl::read_excel(temp, sheet = 1))

# fix colnames
colnames(DSHS_deaths_time) = DSHS_deaths_time[2, ]
DSHS_deaths_time = DSHS_deaths_time[3:(nrow(DSHS_deaths_time) - 10), ]
colnames(DSHS_deaths_time)[1] = 'County'

# melt
DSHS_deaths_long = reshape::melt(DSHS_deaths_time, id = c('County', 'Population'))
                                
# set colnames
colnames(DSHS_deaths_long) = c('County', 'Population', 'Date', 'Deaths_Cumulative')

# fix dates
# DSHS_deaths_long$Date = as.Date(gsub('deaths\r\n\r\n', '', as.character(DSHS_deaths_long$Date)), format = '%y%m%d')
DSHS_deaths_long$Date = as.Date(as.integer(DSHS_deaths_long$Date), origin = '2020-03-03')
```

```{r}
# testing

test_url = 'https://dshs.texas.gov/coronavirus/TexasCOVID-19CumulativeTestsOverTimebyCounty.xlsx'
temp = tempfile()
download.file(test_url, temp, mode = 'wb') 
DSHS_tests_time = data.frame(readxl::read_excel(temp, sheet = 1))

# fix colname
colnames(DSHS_tests_time) = DSHS_tests_time[1, ]
DSHS_tests_time = DSHS_tests_time[2:(nrow(DSHS_tests_time) - 9), ]
colnames(DSHS_tests_time)[1] = 'County'

# melt
DSHS_tests_long = reshape::melt(DSHS_tests_time, id = c('County'))
                                
# set colnames
colnames(DSHS_tests_long) = c('County', 'Date', 'Tests_Cumulative')

# fix dates
DSHS_tests_long$Date = gsub('*', '', DSHS_tests_long$Date, fixed = T)
DSHS_tests_long$Date = as.Date(gsub('Tests Through ', '', DSHS_tests_long$Date), format = '%B%d')

# replace '--' and '-' with NA
DSHS_tests_long$Tests_Cumulative = na_if(DSHS_tests_long$Tests_Cumulative, '-')
DSHS_tests_long$Tests_Cumulative = na_if(DSHS_tests_long$Tests_Cumulative, '--')

DSHS_tests_long$Tests_Cumulative = as.numeric(DSHS_tests_long$Tests_Cumulative)
```


```{r}
# active cases
active_case_url = 'https://dshs.texas.gov/coronavirus/TexasCOVID-19ActiveCaseDatabyCounty.xlsx'
temp = tempfile()
download.file(active_case_url, temp, mode = 'wb') 
DSHS_active_cases_time = data.frame(readxl::read_excel(temp, sheet = 1))

# fix colname
colnames(DSHS_active_cases_time) = DSHS_active_cases_time[2, ]
DSHS_active_cases_time = DSHS_active_cases_time[3:(nrow(DSHS_active_cases_time)), 2:ncol(DSHS_active_cases_time)]
colnames(DSHS_active_cases_time)[1] = 'County'

# melt
DSHS_active_cases_long = reshape::melt(DSHS_active_cases_time, id = c('County'))
                                
# set colnames
colnames(DSHS_active_cases_long) = c('County', 'Date', 'Active_Cases_Cumulative')

# fix dates
DSHS_active_cases_long$Date = as.Date(gsub('Active\r\nCases\r\n', '', DSHS_active_cases_long$Date),
                                      format = '%m-%d')
```

```{r}
# combine DSHS sources
DSHS_county_counts = Reduce(function(x, y) merge(x, y, by = c('County', 'Date'), all=TRUE),
       list(DSHS_cases_long, DSHS_deaths_long, DSHS_tests_long, DSHS_active_cases_long))

# set population for all rows
DSHS_county_counts$Population.x = NULL
colnames(DSHS_county_counts)[colnames(DSHS_county_counts) == 'Population.y'] = 'Population'

DSHS_county_counts$Source = 'DSHS'
```


# STATE LEVEL

## IHME

```{r}
url = 'https://ihmecovid19storage.blob.core.windows.net/latest/ihme-covid19.zip'
all_files = unzip('original-sources/IHME.zip', list = TRUE)
IHME_data = read.csv(unz('original-sources/IHME.zip', all_files[2,1]))
```

Cleaning
```{r}
# drop imported row name
IHME_texas = subset(IHME_data, location_name == 'Texas')[-1]
write.csv(IHME_texas, 'original-sources/IHME.csv', row.names = F)


# restrict to current date & observed tests etc (no real data before)
IHME_texas_current = subset(IHME_texas, as.Date(date) < Sys.Date() & as.Date(date) >= as.Date('2020-02-08') & 
                            mobility_data_type == 'observed' & total_tests_data_type == 'observed')

# format date 
IHME_texas_current$date = as.Date(as.character(IHME_texas_current$date), format = '%Y-%m-%d')

# focus on non-calculated cols, can change later
IHME_calc_cols = grep('upper|lower|est_|smoothed|_mean', names(IHME_texas_current))
IHME_texas_current_raw = IHME_texas_current[, -c(IHME_calc_cols)]

# drop uninformative cols 
IHME_trash_cols = c('bedover_mean', 'icuover_mean', 'mobility_data_type', 'total_tests_data_type')
IHME_texas_current_raw = IHME_texas_current_raw[, !(names(IHME_texas_current_raw) %in% IHME_trash_cols)]

# TODO: look at methodology for colname meanings, appears that all _mean cols are projections as well - omitting for now
# colnames(IHME_texas_current_raw) = c('State', 'Date', 'All_Bed_Mean', 'ICU_Bed_Mean', 'Ventilator_Cumulative',
#                                      'Deaths_Cumulative', 'Admissions', 'New_ICU', 'Deaths_Total',
#                                      'Mobility_Composite', 'Tests_Total', 'Infection_Total')

# need denominator for tests and infections
colnames(IHME_texas_current_raw) = c('State', 'Date', 'Mobility_Composite', 'Tests_Total', 'Infections_Total')

IHME_texas_current_raw$Source = 'IHME'
IHME_texas_current_raw$Type = 'Longitudinal'
```

## Covidtracking.com

```{r}
COVIDTRACKING_data = read.csv(url('https://covidtracking.com/api/v1/states/daily.csv'))
```

Cleaning

```{r}
COVID_TRACKING_texas = subset(COVIDTRACKING_data, state == 'TX')
write.csv(COVID_TRACKING_texas, 'original-sources/COVID_TRACKING.csv', row.names = F)

# format date
COVID_TRACKING_texas$date = as.Date(as.character(COVID_TRACKING_texas$date), format = '%Y%m%d')


# drop cols
COVID_TRACKING_trash_cols = c('total', 'posNeg', 'lastUpdateEt', 'hash', 'pending', 'hospitalized', 'dateChecked')
COVID_TRACKING_texas = COVID_TRACKING_texas[, !names(COVID_TRACKING_texas) %in%  COVID_TRACKING_trash_cols]


# NA values for hospital, ICU and ventilator counts 
colnames(COVID_TRACKING_texas) = c('Date', 'State', 'Positive_Total', 'Negative_Total',
                                   'Hospital_Current', 'Hospital_Cumulative', 'ICU_Current', 'ICU_Cumulative',
                                   'Ventilator_Current', 'Ventilator_Cumulative', 'Recovered_Cumulative',
                                   'Quality', 'Deaths_Total', 'Tests_Total', 'FIPS', 'Deaths_New', 'Hospital_New',
                                   'Negative_New', 'Positive_New', 'Tests_New')

COVID_TRACKING_texas$Source = 'Covidtracking'
COVID_TRACKING_texas$Type = 'Longitudinal'
```


## CLAFLIN

```{r}
CLAFLIN_capacity_20 = gsheet::gsheet2tbl('https://docs.google.com/spreadsheets/d/1XUVyZF3X_4m72ztFnXZFvDKn5Yys1aKgu2Zmefd7wVo/edit?fbclid=IwAR3fi4RzFRBZqolwpKY-g20BXHLyltp18rgCrzKX0LLSe_2dkCsimZan_VY#gid=1576394115')

CLAFLIN_capacity_40 = gsheet::gsheet2tbl('https://docs.google.com/spreadsheets/d/1XUVyZF3X_4m72ztFnXZFvDKn5Yys1aKgu2Zmefd7wVo/edit?fbclid=IwAR3fi4RzFRBZqolwpKY-g20BXHLyltp18rgCrzKX0LLSe_2dkCsimZan_VY#gid=98841913')

CLAFLIN_capacity_60 = gsheet::gsheet2tbl('https://docs.google.com/spreadsheets/d/1XUVyZF3X_4m72ztFnXZFvDKn5Yys1aKgu2Zmefd7wVo/edit?fbclid=IwAR3fi4RzFRBZqolwpKY-g20BXHLyltp18rgCrzKX0LLSe_2dkCsimZan_VY#gid=0')
```

Cleaning

```{r}
CLAFLIN_capacity_20$Infection_Rate = '20'
CLAFLIN_capacity_40$Infection_Rate = '40'
CLAFLIN_capacity_60$Infection_Rate = '60'

CLAFLIN_combined = rbind(CLAFLIN_capacity_20, CLAFLIN_capacity_40, CLAFLIN_capacity_60)
CLAFLIN_texas = subset(CLAFLIN_combined, State == 'TX')
write.csv(CLAFLIN_texas, 'original-sources/CLAFIN.csv', row.names = F)
# doesn't appear to change over time, still set for merging purposes
CLAFLIN_texas$Date = Sys.Date() - 1

CLAFLIN_texas$Source = 'CLAFLIN'
CLAFLIN_texas$Type = 'Static'

# drop projections
CLAFLIN_calc_cols = grep('Projected|Proejcted', names(CLAFLIN_texas))
CLAFLIN_texas = CLAFLIN_texas[, !(names(CLAFLIN_texas) %in% CLAFLIN_calc_cols)]

#Rename - omit merging for now due to length of unique cols, will still output as .csv for easier analysis
colnames(CLAFLIN_texas) = 
    c('State', 'All_Bed_Total', 'ICU_Bed_Total', 'Hospital_Bed_Occupancy', 'ICU_Bed_Occupancy',
    'Hospital_Bed_Available', 'Hospital_Bed_Potential',
    'ICU_Bed_Available', 'ICU_Bed_Potential', 'Pop_Over_65_Total',
    'Hospital_Bed_Need_6mo', 'Hospital_Bed_Need_PCT_6mo', 'Hospital_Bed_Potential_Need_PCT_6mo', 'Hospital_Bed_Total_Need_PCT_6mo',
    'Hospital_Bed_Need_12mo', 'Hospital_Bed_Need_PCT_12mo', 'Hospital_Bed_Potential_Need_PCT_12mo', 'Hospital_Bed_Total_Need_PCT_12mo',
    'Hospital_Bed_Need_12mo', 'Hospital_Bed_Need_PCT_12mo', 'Hospital_Bed_Potential_Need_PCT_12mo', 'Hospital_Bed_Total_Need_PCT_12mo',
    'ICU_Bed_Need_6mo', 'ICU_Bed_Need_PCT_6mo', 'ICU_Bed_Potential_Need_PCT_6mo', 'ICU_Bed_Total_Need_PCT_6mo',
    'ICU_Bed_Need_12mo', 'ICU_Bed_Need_PCT_12mo', 'ICU_Bed_Potential_Need_PCT_12mo', 'ICU_Bed_Total_Need_PCT_12mo',
    'ICU_Bed_Need_12mo', 'ICU_Bed_Need_PCT_12mo', 'ICU_Bed_Potential_Need_PCT_12mo', 'ICU_Bed_Total_Need_PCT_12mo',
    'Infection_Rate')
```

## DSHS (time series)

```{r}
download.file('https://www.dshs.state.tx.us/coronavirus/TexasCOVID19CaseCountData.xlsx',
               destfile = 'original-sources/dshs.xlsx', mode = 'wb')

library(readxl)
read_excel_allsheets = function(filename, tibble = FALSE) {
    sheets = readxl::excel_sheets(filename)
    x = lapply(sheets, function(X) readxl::read_excel(filename, sheet = X, skip = 1, col_names = TRUE))
    x = lapply(x, as.data.frame)
    return(x)
}

DSHS_data = read_excel_allsheets('original-sources/dshs.xlsx')
```


```{r}
DSHS_tests = DSHS_data[[4]]
DSHS_tests = DSHS_tests[1:(nrow(DSHS_tests)-3), ]

colnames(DSHS_tests) = c('Date', 'Viral_Tests', 'Antibody_Tests', 'Total_Tests', 'Positive_Rate', 'Viral_Tests_New_Avg', 'Antibody_Tests_New_Avg', 'Total_Tests_New_Avg')

# fix date (https://stackoverflow.com/questions/43230470/how-to-convert-excel-date-format-to-proper-date-in-r) 
DSHS_tests$Date = as.Date(as.integer(DSHS_tests$Date), origin = '1899-12-30')

# fix calc col type
DSHS_tests$Positive_Rate = as.numeric(DSHS_tests$Positive_Rate)
```


```{r}
# drop row num
DSHS_hospitalizations = DSHS_data[[8]][, c(2:3)]

# drop footnote
DSHS_hospitalizations = DSHS_hospitalizations[1:(nrow(DSHS_hospitalizations)-2), ]

# fix date
DSHS_hospitalizations$Date = as.Date(DSHS_hospitalizations$Date, format = '%Y%m%d')

# set colnames
colnames(DSHS_hospitalizations)[2] = 'Hospital_Total'
```


```{r}
# merge tests & hospitalizations
DSHS_state_time = merge(DSHS_tests, DSHS_hospitalizations, by = 'Date')

# add descriptors
DSHS_state_time$Source = 'DSHS'
DSHS_state_time$Type = 'Longitudinal'
```

## DSHS (day counts)

```{r}
# avoids duplication of results between sheets
DSHS_day_counts = data.frame(Date = Sys.Date() - 1,
                             Source = 'DSHS',
                             Type = 'Current',  # (not longitudinal)
                             Recovered_Total = DSHS_data[[3]][1,1],
                             Active_Total = DSHS_data[[3]][1,2],
                             Tests_State_Lab = DSHS_data[[5]][1,2],
                             Tests_Commercial_Lab = DSHS_data[[5]][2,2],
                             Antibody_Tests_Positive = DSHS_data[[6]][2,2],
                             Hospital_Bed_Total = DSHS_data[[7]][2,2],
                             Hospital_Bed_Available = DSHS_data[[7]][3,2],
                             ICU_Bed_Available = DSHS_data[[7]][4,2],
                             Ventilator_Available = DSHS_data[[7]][5,2],
                             Case_Investigations = DSHS_data[[9]][[14,2]],
                             Death_Investigations = DSHS_data[[12]][14,2])
```

## DSHS Demographics

### Cases
```{r}
#Age
DSHS_case_age = DSHS_data[[9]][1:(nrow(DSHS_data[[9]])-4), ]
colnames(DSHS_case_age)[1] = 'Group'
DSHS_case_age$Demographic = 'Age'
DSHS_case_age$Source = 'DSHS'
DSHS_case_age$Type = 'Current'
DSHS_case_age$Count_Type = 'Case'
DSHS_case_age$Date = Sys.Date()-1

#Gender
DSHS_case_gender = DSHS_data[[10]][1:(nrow(DSHS_data[[10]])-4), ]
colnames(DSHS_case_gender)[1] = 'Group'
DSHS_case_gender$Demographic = 'Gender'
DSHS_case_gender$Source = 'DSHS'
DSHS_case_gender$Type = 'Current'
DSHS_case_gender$Count_Type = 'Case'
DSHS_case_gender$Date = Sys.Date()-1

# Race
DSHS_case_race = DSHS_data[[11]][1:(nrow(DSHS_data[[11]])-4), ]
colnames(DSHS_case_race)[1] = 'Group'
DSHS_case_race$Demographic = 'Race'
DSHS_case_race$Source = 'DSHS'
DSHS_case_race$Type = 'Current'
DSHS_case_race$Count_Type = 'Case'
DSHS_case_race$Date = Sys.Date()-1
```

### Deaths
```{r}
#Age
DSHS_death_age = DSHS_data[[12]][1:(nrow(DSHS_data[[12]])-4), ]
colnames(DSHS_death_age)[1] = 'Group'
DSHS_death_age$Demographic = 'Age'
DSHS_death_age$Source = 'DSHS'
DSHS_death_age$Type = 'Current'
DSHS_death_age$Count_Type = 'Death'
DSHS_death_age$Date = Sys.Date()-1

#Gender
DSHS_death_gender = DSHS_data[[13]][1:(nrow(DSHS_data[[13]])-4), ]
DSHS_death_gender$Demographic = 'Gender'
colnames(DSHS_death_gender)[1] = 'Group'
DSHS_death_gender$Source = 'DSHS'
DSHS_death_gender$Type = 'Current'
DSHS_death_gender$Count_Type = 'Death'
DSHS_death_gender$Date = Sys.Date()-1

# Race
DSHS_death_race = DSHS_data[[14]][1:(nrow(DSHS_data[[14]])-4), ]
DSHS_death_race$Demographic = 'Race'
colnames(DSHS_death_race)[1] = 'Group'
DSHS_death_race$Source = 'DSHS'
DSHS_death_race$Type = 'Current'
DSHS_death_race$Count_Type = 'Death'
DSHS_death_race$Date = Sys.Date()-1
```

```{r}
# combine 
DSHS_demographics = rbind(DSHS_case_age, DSHS_case_gender, DSHS_case_race, 
                          DSHS_death_age, DSHS_death_gender, DSHS_death_race)

# change colnames
colnames(DSHS_demographics) = c('Demo_Group', 'Demo_Count', 'Demo_PCT', 'Demographic',
                                'Source', 'Type', 'Investigation_Type', 'Date')
```


# TBD 

## KFF

<!-- Omitting due to JS scraping requirements - could be done in python if considered valuable source -->

```{r}
# KFF_beds = read.csv(url('https://www.kff.org/other/state-indicator/beds-by-ownership/?currentTimeframe=0&sortModel=%7B%22colId%22:%22Location%22,%22sort%22:%22asc%22%7D'))
```



##  Our World in Data

<!-- Only has US level data - omitting for now -->

<!-- ```{r} -->
<!-- OUR_WORLD_data = read.csv(url('https://covid.ourworldindata.org/data/owid-covid-data.csv')) -->
<!-- ``` -->

<!--  Cleaning -->
<!-- ```{r} -->

## Additional sources from tableau

# OUTPUT 

## County Level

```{r}
#rbind fills mismatched cols with NA (NYT has less vars than JHU)
merged_counts1 = rbind.fill(JHU_texas_long, NYT_texas)
merged_counts2 = rbind.fill(merged_counts1, US_FACTS_texas_long)
merged_counts3 = rbind.fill(merged_counts2, DSHS_county_counts)

# add google mobility - colbind this time since other data source likely not available
# outer join b/c google only has data on 220 counties (JHU has 254 and more dates)
merged_counts4 = as.data.frame(merge(merged_counts3, mobility_texas[, c(2:9)], by = c('County', 'Date'), all = TRUE))
```

```{r}
# fix types
merged_counts4$Source = as.factor(merged_counts4$Source)
merged_counts4$County = as.factor(merged_counts4$County)
merged_counts4$State = as.factor(merged_counts4$State)

# replace TX with Texas
merged_counts4$State = droplevels(revalue(merged_counts4$State, c('TX' = 'Texas')))
```


```{r}
# declare metro and border designations
Metro = c("Aransas", "Archer", "Armstrong", "Atascosa", "Austin", "Bandera", "Bastrop", "Bell", "Bexar", "Bowie", "Brazoria", "Brazos", "Burleson", "Caldwell", "Callahan", "Cameron", "Carson", "Chambers", "Clay", "Collin", "Comal", "Coryell", "Crosby", "Dallas", "Denton", "Ector", "Ellis", "El Paso", "Falls", "Fort Bend", "Galveston", "Goliad", "Grayson", "Gregg", "Guadalupe", "Hardin", "Harris", "Hays", "Hidalgo", "Hood", "Hudspeth", "Hunt", "Irion", "Jefferson", "Johnson", "Jones", "Kaufman", "Kendall", "Lampasas", "Liberty", "Lubbock", "Lynn", "McLennan", "Martin", "Medina", "Midland", "Montgomery", "Newton", "Nueces", "Oldham", "Orange", "Parker", "Potter", "Randall", "Robertson", "Rockwall", "Rusk", "San Patricio", "Smith", "Somervell", "Tarrant", "Taylor", "Tom Green", "Travis", "Upshur", "Victoria", "Waller", "Webb", "Wichita", "Williamson", "Wilson", "Wise")

Border = c("Brewster", "Brooks", "Cameron", "Crockett", "Culberson", "Dimmit", "Duval", "Edwards", "El Paso", "Frio", "Hidalgo", "Hudspeth", "Jeff Davis", "Jim Hogg", "Kenedy", "Kinney", "La Salle", "McMullen", "Maverick", "Pecos", "Presidio", "Real", "Reeves", "Starr", "Sutton", "Terrell", "Uvalde", "Val Verde", "Webb", "Willacy", "Zapata", "Zavala")
```

```{r}
# add metro and border designations
merged_counts4$Metro = ifelse(merged_counts4$County %in% Metro, 'Metro', 'Nonmetro')
merged_counts4$Border = ifelse(merged_counts4$County %in% Border, 'Border', 'Nonborder')
```

```{r}
# add service regions (adapted from https://www.dshs.texas.gov/chs/info/info_txco.shtm)
service_regions = read.csv('original-sources/service_regions.csv')

# drop x added to end of regions interpreted as dates
service_regions$Health.Service.Region = as.character(service_regions$Health.Service.Region)
service_regions$Health.Service.Region = gsub('x', '', service_regions$Health.Service.Region)

# set colnames
colnames(service_regions) = c('County_Num', 'County', 'FIPS', 'Public_Health_Region', 'Health_Service_Region')

# merge with data
merged_counts5 = merge(merged_counts4, service_regions[2:5], by = 'County')


# make FIPS uniform
merged_counts5$FIPS.x = NULL
colnames(merged_counts5)[colnames(merged_counts5) == 'FIPS.y'] = 'FIPS'
```


```{r}
# TSA levels
tsa = read.csv('original-sources/tsa_list.csv', header = F)[-1]
tsa_long = reshape::melt(tsa, id = c('V2'))
tsa_long_complete = subset(tsa_long, value != '')[, c(1,3)]
colnames(tsa_long_complete) = c('TSA', 'County')


tsa_long_complete$County = trimws(tsa_long_complete$County)

merged_counts6 = merge(merged_counts5, tsa_long_complete, by = 'County', all = TRUE)
```



```{r}
# sort by county, date and export
merged_counts6 = merged_counts6[order(merged_counts6$County, merged_counts6$Date), ]
write.csv(merged_counts6, file = 'combined-datasets/county_counts.csv', row.names = F)
```

## State Level

```{r}
merged_state1 = rbind.fill(IHME_texas_current_raw, COVID_TRACKING_texas)
merged_state2 = rbind.fill(merged_state1, DSHS_state_time)
merged_state3 = rbind.fill(merged_state2, DSHS_day_counts)
merged_state4 = rbind.fill(merged_state3, DSHS_demographics)
```

```{r}
# additional postprocessing
merged_state4$State = 'Texas'
```


```{r}
write.csv(merged_state4, file = 'combined-datasets/state_tests_hosp.csv', row.names = F)
```

## Additional csvs

```{r}
write.csv(CLAFLIN_texas, 'combined-datasets/claflin_capacity.csv', row.names = F)
write.csv(DSHS_demographics, 'combined-datasets/demographics.csv', row.names = F)
```
