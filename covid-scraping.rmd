---
title: 'COVID Scraping'
author: 'Jeffrey Brennan'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#knitr::opts_knit$set(root.dir = "C:/Users/jeffb/Desktop/Life/personal-projects/COVID")

library(data.table)
library(readxl)
library(dplyr)
library(stringr)
```

```{r helper functions}
read_excel_allsheets = function(filename, tibble = FALSE) {
    sheets = readxl::excel_sheets(filename)
    x = lapply(sheets, function(X) readxl::read_excel(filename, sheet = X, skip = 1, col_names = TRUE, na = '.'))
    x = lapply(x, as.data.frame)
    return(x)
}
```


# TODO 

```{r}
# TODO: investigate 
# https://covidtracking.com/race
```


# CENSUS 

## County level

```{r}
# sourced from https://www.census.gov/data/tables/time-series/demo/popest/2010s-counties-detail.html
county_demo = read.csv('original-sources/census/county_demo.csv')

# restrict to 2018 pop estimate & drop extra cols
county_demo_2018 = subset(county_demo[, c(5:ncol(county_demo))], YEAR == 11)

# drop year
county_demo_2018$YEAR = NULL

# drop 'county' suffix
county_demo_2018$CTYNAME = gsub(' County', '', county_demo_2018$CTYNAME)

# drop agegrp = 0 (total row)
county_demo_2018 = county_demo_2018[which(county_demo_2018$AGEGRP != 0), ]

# rename cols for merging
colnames(county_demo_2018)[1] = 'County'

# add age labels
county_demo_2018$AGEGRP = factor(county_demo_2018$AGEGRP,
                                 labels = c('0-4', '5-9', '10-14', '15-19', '20-24', '25-29',
                                            '30-34', '35-39', '40-44', '45-49', '50-54', '55-59',
                                            '60-64',  '65-69', '70-74', '75-79', '80-84', '85+'))
```


## City level

```{r}
# keep only 2018 estimate
city_pops = read.csv('original-sources/census/city_pops.csv')[, c(3, 4, 9, 21)]

colnames(city_pops) = c('County', 'Place_Code', 'City', 'Population')

# drop city, town, suffixes
city_pops$City = gsub(' city| town|', '', city_pops$City)

# drop pt suffix
# pt indicates overlap of cities between counties
city_pops$City = gsub(' (pt.)', '', city_pops$City, fixed = TRUE)

colnames(city_pops)[1] = 'County_Code'

# get county fips
county_fips = subset(city_pops, Place_Code == 0)[-1, c(1,3)]
colnames(county_fips) = c('County_Code', 'County')


# replace county fips with actual names
merged_city = merge(city_pops, county_fips, by = 'County_Code')

# drop county totals from list
merged_city = subset(merged_city, Place_Code != 0 & Place_Code != 99990)

# drop county suffix
merged_city$County = gsub(' County', '', merged_city$County)
```


# COUNTY LEVEL

## Google mobility

Used fread for faster import - very large file

```{r}
mobility_data = fread('https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv')
```

```{r}
# filter mobility
mobility_texas = subset(mobility_data, sub_region_1 == 'Texas')

# drop cols
mobility_texas = mobility_texas[, -c(1,2,3,5,6)]
write.csv(mobility_texas, 'original-sources/GOOGLE.csv', row.names = F)

# fix colnames
# values represent percent change from baseline
colnames(mobility_texas) = c('County', 'Date', 'Retail_Recreation', 'Grocery_Pharmacy',
                             'Parks', 'Transit', 'Workplaces', 'Residential')

# Add name for blank county cells & drop 'county' suffix
mobility_texas$County = sub('^$', 'Unallocated', mobility_texas$County)
mobility_texas$County = gsub(' County', '', mobility_texas$County)

# drop blank cells
mobility_texas = subset(mobility_texas, County != 'Unallocated')

#fix types
mobility_texas$County = as.factor(mobility_texas$County)
mobility_texas$Date = as.Date(mobility_texas$Date)
```


## DSHS 

### cases

```{r}
case_url = 'http://dshs.texas.gov/coronavirus/TexasCOVID19DailyCountyCaseCountData.xlsx'
temp = tempfile()
download.file(case_url, temp, mode = 'wb') 
DSHS_cases_time = data.frame(readxl::read_excel(temp, sheet = 1))

# fix colnames
colnames(DSHS_cases_time) = DSHS_cases_time[2, ]
DSHS_cases_time = DSHS_cases_time[3:(nrow(DSHS_cases_time) - 11), ]
colnames(DSHS_cases_time)[1] = 'County'

#save
write.csv(DSHS_cases_time, 'original-sources/DSHS_county_cases.csv', row.names = FALSE)

# melt
DSHS_cases_long = reshape::melt(DSHS_cases_time, id = c('County', 'Population'))
                                
# set colnames
colnames(DSHS_cases_long) = c('County', 'Population', 'Date', 'Cases_Cumulative')

# fix dates
DSHS_cases_long$Date = as.Date(gsub('Cases|\r|\r|\n', '', DSHS_cases_long$Date), format = '%m-%d')

# sort
DSHS_cases_long = DSHS_cases_long[order(DSHS_cases_long$County, DSHS_cases_long$Date), ]

# calculate daily cases
DSHS_cases_long$Cases_Cumulative = as.integer(as.character(DSHS_cases_long$Cases_Cumulative))
DSHS_cases_long = 
    DSHS_cases_long %>% 
    group_by(County) %>% 
     mutate(Cases_Daily = c(Cases_Cumulative[1], diff(Cases_Cumulative)))
```

### deaths

```{r}
death_url = 'https://dshs.texas.gov/coronavirus/TexasCOVID19DailyCountyFatalityCountData.xlsx'
temp = tempfile()
download.file(death_url, temp, mode = 'wb') 
DSHS_deaths_time = data.frame(readxl::read_excel(temp, sheet = 1))

# fix colnames
colnames(DSHS_deaths_time) = DSHS_deaths_time[2, ]
DSHS_deaths_time = DSHS_deaths_time[3:(nrow(DSHS_deaths_time) - 10), ]
colnames(DSHS_deaths_time)[1] = 'County'

#save
write.csv(DSHS_deaths_time, 'original-sources/DSHS_county_deaths.csv', row.names = FALSE)

# melt
DSHS_deaths_long = reshape::melt(DSHS_deaths_time, id = c('County', 'Population'))
                                
# set colnames
colnames(DSHS_deaths_long) = c('County', 'Population', 'Date', 'Deaths_Cumulative')

# fix dates
DSHS_deaths_long$Date = as.Date(as.integer(DSHS_deaths_long$Date), origin = '2020-03-03')

# calculate daily deaths
DSHS_deaths_long$Deaths_Cumulative = as.integer(as.character(DSHS_deaths_long$Deaths_Cumulative))
DSHS_deaths_long = 
    DSHS_deaths_long %>% 
    group_by(County) %>%
    mutate(Deaths_Daily = c(Deaths_Cumulative[1], diff(Deaths_Cumulative)))
```

### testing

```{r}
test_url = 'https://dshs.texas.gov/coronavirus/TexasCOVID-19CumulativeTestsOverTimebyCounty.xlsx'
temp = tempfile()
download.file(test_url, temp, mode = 'wb') 
DSHS_tests_time = data.frame(readxl::read_excel(temp, sheet = 1))

# TEMP FIX drop first duplicated date column
dupe_dates = which(DSHS_tests_time[1, ] == 'Tests Through June 23')
DSHS_tests_time = DSHS_tests_time[, -dupe_dates[1]]

# fix colnames
colnames(DSHS_tests_time) = DSHS_tests_time[1, ]
DSHS_tests_time = DSHS_tests_time[2:(nrow(DSHS_tests_time) - 9), ]
colnames(DSHS_tests_time)[1] = 'County'

#save
write.csv(DSHS_tests_time, 'original-sources/DSHS_county_tests.csv', row.names = FALSE)

# melt
DSHS_tests_long = reshape::melt(DSHS_tests_time, id = c('County'))
                                
# set colnames
colnames(DSHS_tests_long) = c('County', 'Date', 'Tests_Cumulative')

# fix dates
DSHS_tests_long$Date = gsub('*', '', DSHS_tests_long$Date, fixed = T)
DSHS_tests_long$Date = as.Date(gsub('Tests Through ', '', DSHS_tests_long$Date), format = '%B%d')

# replace '--' and '-' with NA
DSHS_tests_long$Tests_Cumulative = na_if(DSHS_tests_long$Tests_Cumulative, '-')
DSHS_tests_long$Tests_Cumulative = na_if(DSHS_tests_long$Tests_Cumulative, '--')

DSHS_tests_long$Tests_Cumulative = as.numeric(as.character(DSHS_tests_long$Tests_Cumulative))

# calculate daily tests
DSHS_tests_long = 
    DSHS_tests_long %>% 
    group_by(County) %>% 
    mutate(Tests_Daily = c(Tests_Cumulative[1], diff(Tests_Cumulative)))

# drop unmergable counties 
DSHS_tests_long = subset(DSHS_tests_long, County != 'Unknown' & County != 'Pending Assignments')
```

### active cases

```{r}
active_case_url = 'https://dshs.texas.gov/coronavirus/TexasCOVID-19ActiveCaseDatabyCounty.xlsx'
temp = tempfile()
download.file(active_case_url, temp, mode = 'wb') 
DSHS_active_cases_time = data.frame(readxl::read_excel(temp, sheet = 1))

# fix colname
colnames(DSHS_active_cases_time) = DSHS_active_cases_time[2, ]
DSHS_active_cases_time = DSHS_active_cases_time[3:(nrow(DSHS_active_cases_time)), 2:ncol(DSHS_active_cases_time)]
colnames(DSHS_active_cases_time)[1] = 'County'

#save
write.csv(DSHS_active_cases_time, 'original-sources/DSHS_county_active_cases.csv', row.names = FALSE)

# melt
DSHS_active_cases_long = reshape::melt(DSHS_active_cases_time, id = c('County'))
                                
# set colnames
colnames(DSHS_active_cases_long) = c('County', 'Date', 'Active_Cases_Cumulative')

# fix dates
DSHS_active_cases_long$Date = as.Date(gsub('Active|Cases|\r|\n', '', DSHS_active_cases_long$Date),
                                      format = '%m-%d')

# manually fix last date (mistakenly coded by DSHS as 07-30)
if (Sys.Date() < as.Date('2020-07-30')) {
  DSHS_active_cases_long$Date[DSHS_active_cases_long$Date == as.Date('2020-07-30')] = as.Date('2020-06-30')
  }

# calculate daily active_cases
DSHS_active_cases_long$Active_Cases_Cumulative = as.integer(as.character(DSHS_active_cases_long$Active_Cases_Cumulative))
DSHS_active_cases_long =  
    DSHS_active_cases_long %>% 
    group_by(County) %>% 
    mutate(Active_Cases_Daily = c(Active_Cases_Cumulative[1], diff(Active_Cases_Cumulative)))
```

```{r}
# combine DSHS sources
DSHS_county_counts = Reduce(function(x, y) merge(x, y, by = c('Date', 'County'), all=TRUE),
       list(DSHS_cases_long, DSHS_deaths_long, DSHS_tests_long, DSHS_active_cases_long))


# drop population - will be using census data
DSHS_county_counts$Population.x = NULL
DSHS_county_counts$Population.y = NULL
```

## Classifications

```{r}
# add metro and PHR designations from https://www.dshs.state.tx.us/chs/info/TxCoPhrMsa.xls]\
county_classifications = read_xlsx('original-sources/county_classifications.xlsx', sheet = 1)[1:254, c(1, 5, 8)]

# set colnames
colnames(county_classifications) = c('County', 'PHR', 'Metro_Area')

# add PHR names from https://dshs.texas.gov/regions/default.shtm
PHR_helper = data.frame(PHR = unique(county_classifications$PHR))
PHR_helper$PHR_Name = c('Tyler PHR', 'El Paso PHR', 'Harlingen PHR', 
                        'Arlington PHR', 'Lubbock PHR', 'San Antonio PHR',
                        'Houston PHR', 'Temple PHR')

county_classifications = merge(county_classifications, PHR_helper, by = 'PHR')
```


```{r}
# merged_counts2 = merge(merged_counts, county_classifications, by = 'County')
```

```{r}
# TSA levels
tsa = read.csv('original-sources/tsa_list.csv', header = F)[-1]
tsa_long = reshape::melt(tsa, id = c('V2', 'V3'))
tsa_long_complete = subset(tsa_long, value != '')[, c(1, 2, 4)]
colnames(tsa_long_complete) = c('TSA', 'TSA_Name', 'County')

tsa_long_complete$County = trimws(tsa_long_complete$County)
tsa_long_complete$TSA_Name = trimws(tsa_long_complete$TSA_Name)


# merged_counts3 = merge(merged_counts2, tsa_long_complete, by = 'County', all = TRUE)

# sort by county, date
# merged_counts3 = merged_counts3[order(merged_counts3$County, merged_counts3$Date), ]
```

## merge

```{r}
# DSHS pop
dshs_pops = unique(DSHS_cases_long[, c(1:2)])
colnames(dshs_pops) = c('County', 'Population_DSHS')

merged_dshs = Reduce(function(x, y) merge(x, y, by = 'County', all = TRUE),
                       list(DSHS_county_counts, tsa_long_complete, dshs_pops, county_classifications))

# add TSA & PHR combination
merged_dshs$TSA_Combined = paste0(merged_dshs$TSA, ' - ', merged_dshs$TSA_Name)
merged_dshs$PHR_Combined = paste0(merged_dshs$PHR, ' - ', merged_dshs$PHR_Name)

merged_county = as.data.frame(merge(merged_dshs, mobility_texas, by = c('Date', 'County'), all = TRUE))

# fix types
merged_county$County = as.factor(merged_county$County)
merged_county$Population_DSHS = as.numeric(merged_county$Population_DSHS)

# keep only relevant dates
merged_county = subset(merged_county, Date >= as.Date('2020-03-04'))
```

# TSA LEVEL

## Computed

```{r}
DSHS_tsa_counts =
    merged_county %>%
    group_by(Date, TSA, TSA_Name) %>% 
    summarize_at(vars(Cases_Cumulative, Cases_Daily,
                      Deaths_Cumulative, Deaths_Daily,
                      Tests_Cumulative, Tests_Daily,
                      Active_Cases_Cumulative, Active_Cases_Daily),
                 funs(sum))

DSHS_tsa_pops = 
  subset(merged_county, Date == '2020-03-04') %>%
  group_by(TSA) %>%
  summarize_at(vars(Population_DSHS),
               funs(sum))

DSHS_tsa_google = 
  merged_county %>%
  group_by(Date, TSA, TSA_Name) %>%
  summarize_at(vars(Retail_Recreation, Grocery_Pharmacy,
                    Parks, Transit,
                    Workplaces, Residential),
               funs(weighted.mean(., Population_DSHS)), na.rm = TRUE)

DSHS_tsa = merge(DSHS_tsa_counts, DSHS_tsa_google, by = c('Date', 'TSA', 'TSA_Name'))
DSHS_tsa = merge(DSHS_tsa, DSHS_tsa_pops, by = 'TSA', all = TRUE)
```

## DSHS hospitals

```{r}
hosp_url = 'https://dshs.texas.gov/coronavirus/TexasCOVID-19HospitalizationsOverTimebyTSA.xlsx'
download.file(hosp_url, 'original-sources/DSHS_tsa_hosp.xlsx', mode = 'wb') 
DSHS_tsa_hosp = read_excel_allsheets('original-sources/DSHS_tsa_hosp.xlsx')

DSHS_hosp_clean = function(df, var_name) { 
  colnames(df) = df[1, ]
  df = df[2:23, ]
  df$`TSA ID` = gsub('.', '', df$`TSA ID`, fixed = TRUE)
  df$`TSA AREA` = NULL   # TODO: remove if switch to DSHS
  df_long = reshape::melt(df, id = 'TSA ID')
  colnames(df_long) = c('TSA', 'Date', var_name)
  df_long$Date = as.Date(df_long$Date)
  
  return(df_long)
}

hosp_1 = DSHS_hosp_clean(DSHS_tsa_hosp[[1]], 'Hospitalizations_Total')
hosp_2 = DSHS_hosp_clean(DSHS_tsa_hosp[[2]], 'Hospitalizations_General')
hosp_3 = DSHS_hosp_clean(DSHS_tsa_hosp[[3]], 'Hospitalizations_ICU')
```


## hospital capacity

```{r}
hosp_cap_url = 'https://dshs.texas.gov/coronavirus/TexasHospitalCapacityoverTimebyTSA.xlsx'
download.file(hosp_cap_url, 'original-sources/DSHS_tsa_hosp_cap.xlsx', mode = 'wb') 
DSHS_tsa_hosp_cap = read_excel_allsheets('original-sources/DSHS_tsa_hosp_cap.xlsx')

hosp_cap1 = DSHS_hosp_clean(DSHS_tsa_hosp_cap[[1]], 'Beds_Available_Total')
hosp_cap2 = DSHS_hosp_clean(DSHS_tsa_hosp_cap[[2]], 'Beds_Available_ICU')
hosp_cap3 = DSHS_hosp_clean(DSHS_tsa_hosp_cap[[3]], 'Beds_Occupied_Total')
hosp_cap4 = DSHS_hosp_clean(DSHS_tsa_hosp_cap[[4]], 'Beds_Occupied_ICU')

hosp_cap4$Beds_Occupied_ICU = gsub('--', NA, hosp_cap4$Beds_Occupied_ICU)
```

## DSHS dashboard

```{r}
library(jsonlite)
DSHS_json_hosp_tsa = fromJSON("https://services5.arcgis.com/ACaLB9ifngzawspq/arcgis/rest/services/DSHS_COVID_Hospital_Data/FeatureServer/0/query?f=json&where=1%3D1&returnGeometry=false&spatialRel=esriSpatialRelIntersects&outFields=*&outSR=102100&resultOffset=0&resultRecordCount=25&resultType=standard&cacheHint=true")[['features']][['attributes']]

DSHS_json_hosp_tsa = DSHS_json_hosp_tsa[, c(2,5:9)]

colnames(DSHS_json_hosp_tsa) = c('TSA', 'Hospital_Beds_Staffed', 'Hospital_Beds_Available',
                                 'ICU_Beds_Available', 'Ventilators_Available', 'Current_Cases')

date_out = ifelse((Sys.time() < as.POSIXct(paste0(Sys.Date(), '20:00'), tz = 'America/Chicago')),
                   Sys.Date() - 1,
                   Sys.Date())

date_out = as.Date(date_out, origin = '1970-1-1')

DSHS_json_hosp_tsa$Date = format(date_out, '%m/%d/%y')

# add computed cols
DSHS_json_hosp_tsa = DSHS_json_hosp_tsa %>%
                    mutate(Hospital_Beds_Taken = Hospital_Beds_Staffed - Hospital_Beds_Available - Current_Cases)

# export todays file
write.csv(DSHS_json_hosp_tsa, paste0('original-sources/historical/hosp/tsa_hosp_', date_out, '.csv'),
          row.names = FALSE)

# read in all files
hosp_list <- paste0('original-sources/historical/hosp/',
                    list.files(path = 'original-sources/historical/hosp',
                               pattern = '*.csv'))


tsa_all_hosp = lapply(hosp_list, read.csv, fileEncoding = 'UTF-8-BOM')
tsa_combined_hosp = rbindlist(tsa_all_hosp, fill = TRUE)

tsa_combined_hosp$Date = as.Date(tsa_combined_hosp$Date, format = '%m/%d/%y')
# save
write.csv(tsa_combined_hosp, 'original-sources/DSHS_tsa_hosp_detail.csv', row.names = FALSE)


# only keep vents
tsa_combined_hosp = tsa_combined_hosp[, c('TSA', 'Date', 'Ventilators_Available')]
```


## merge

```{r}
merged_tsa = Reduce(function(x, y) merge(x, y, by = c('Date', 'TSA'), all = TRUE),
                    list(DSHS_tsa, tsa_combined_hosp,
                         hosp_1, hosp_2, hosp_3,
                         hosp_cap1, hosp_cap2, hosp_cap3, hosp_cap4))

# fix types
merged_tsa = merged_tsa %>% 
  mutate_at(vars(Beds_Available_Total, Ventilators_Available, Beds_Available_ICU,
                 Beds_Occupied_Total, Beds_Occupied_ICU, Hospitalizations_Total,
                 Hospitalizations_General, Hospitalizations_ICU),
            funs(as.numeric))
```

# PHR LEVEL

## computed

```{r}
DSHS_phr_counts =
    merged_county %>%
    group_by(Date, PHR, PHR_Name) %>%
    summarize_at(vars(Cases_Cumulative, Cases_Daily,
                      Deaths_Cumulative, Deaths_Daily,
                      Tests_Cumulative, Tests_Daily,
                      Active_Cases_Cumulative, Active_Cases_Daily),
                 funs(sum))

DSHS_phr_pops = 
  subset(merged_county, Date == '2020-03-04') %>%
  group_by(PHR) %>%
  summarize_at(vars(Population_DSHS),
               funs(sum))

DSHS_phr_google = 
  merged_county %>%
  group_by(Date, PHR) %>%
  summarize_at(vars(Retail_Recreation, Grocery_Pharmacy,
                    Parks, Transit,
                    Workplaces, Residential),
               funs(weighted.mean(., Population_DSHS)), na.rm = TRUE)

DSHS_phr = merge(DSHS_phr_counts, DSHS_phr_google, by = c('Date', 'PHR'))
DSHS_phr = merge(DSHS_phr, DSHS_phr_pops, by = c('PHR'), all = TRUE)
```

## fac totals

```{r}

# Duplicate of longitudinal data

# # note: overwritten daily
# download.file('https://dshs.texas.gov/coronavirus/COVID-19OutbreaksinLong-termCareFacilities.xlsx',
#                destfile = 'original-sources/DSHS_fac_totals.xlsx', mode = 'wb')
# 
# download.file('https://dshs.texas.gov/coronavirus/COVID-19OutbreaksinLong-termCareFacilities.xlsx',
#                destfile = paste0('original-sources/historical/nursing/DSHS_fac_totals_', Sys.Date(), '.xlsx'),
#                mode = 'wb')
#               
# DSHS_fac_totals = read_excel_allsheets('original-sources/DSHS_fac_totals.xlsx')

# make df 

# colnames(DSHS_fac_totals[[1]]) = c('PHR', 'Facility_Total','Resident_Cases',
#                             'Resident_Deaths', 'Resident_Recoveries')
# DSHS_fac_totals[[1]][, 'Facility_Type'] = 'Nursing Home'
# 
# colnames(DSHS_fac_totals[[2]]) = c('PHR', 'Facility_Total','Resident_Cases',
#                             'Resident_Deaths', 'Resident_Recoveries')
# DSHS_fac_totals[[2]][, 'Facility_Type'] = 'Assisted Living'
# 
# DSHS_fac_totals_df = rbindlist(DSHS_fac_totals)


```

## alf

```{r}
download.file('https://dshs.texas.gov/coronavirus/COVID-19inALFsoverTimebyRegion.xlsx',
               destfile = 'original-sources/DSHS_alf.xlsx', mode = 'wb')

DSHS_alf = read_excel_allsheets('original-sources/DSHS_alf.xlsx')

Clean_Facility = function(df, count_type) { 
  df = df[1:8, ]
  colnames(df)[1] = 'PHR'
  df_long = reshape::melt(df, id = 'PHR')
  
  colnames(df_long) = c('PHR', 'Date', count_type)
  df_long$Date = as.Date(as.integer(df_long$Date), origin = '2020-05-14')
  
  return(df_long)
  }

alf_fac_totals = Clean_Facility(DSHS_alf[[1]], 'ALF_Total')
alf_cases = Clean_Facility(DSHS_alf[[2]], 'ALF_Cases')
alf_deaths = Clean_Facility(DSHS_alf[[3]], 'ALF_Deaths')
alf_recoveries = Clean_Facility(DSHS_alf[[4]], 'ALF_Recoveries')

alf_df = Reduce(function(x, y) merge(x, y, by = c('Date', 'PHR'), all = TRUE),
                list(alf_fac_totals, alf_cases, alf_deaths, alf_recoveries))
```

## nursing

```{r}
download.file('https://dshs.texas.gov/coronavirus/COVID-19inNursingHomesoverTimebyRegion.xlsx',
               destfile = 'original-sources/DSHS_nursing.xlsx', mode = 'wb')

DSHS_nursing = read_excel_allsheets('original-sources/DSHS_nursing.xlsx')

nursing_fac_totals = Clean_Facility(DSHS_nursing[[1]], 'Nursing_Total')
nursing_cases = Clean_Facility(DSHS_nursing[[2]], 'Nursing_Cases')
nursing_deaths = Clean_Facility(DSHS_nursing[[3]], 'Nursing_Deaths')
nursing_recoveries = Clean_Facility(DSHS_nursing[[4]], 'Nursing_Recoveries')

nursing_df = Reduce(function(x, y) merge(x, y, by = c('Date', 'PHR'), all = TRUE),
                list(nursing_fac_totals, nursing_cases, nursing_deaths, nursing_recoveries))
```

## merge

```{r}
phr_df = Reduce(function(x, y) merge(x, y, by = c('Date', 'PHR'), all = TRUE),
                list(DSHS_phr, alf_df, nursing_df))

# address error when knitting despite str(phr_df indicating all calc columns are numeric)
phr_df$Nursing_Cases = as.numeric(phr_df$Nursing_Cases)
phr_df$Nursing_Recoveries = as.numeric(phr_df$Nursing_Recoveries)
```

# METRO LEVEL

## computed

```{r}
DSHS_metro_counts =
    merged_county %>%
    group_by(Date, Metro_Area) %>%
    summarize_at(vars(Cases_Cumulative, Cases_Daily,
                      Deaths_Cumulative, Deaths_Daily,
                      Tests_Cumulative, Tests_Daily,
                      Active_Cases_Cumulative, Active_Cases_Daily),
                 funs(sum))

DSHS_metro_pops = 
  subset(merged_county, Date == '2020-03-04') %>%
  group_by(Metro_Area) %>%
  summarize_at(vars(Population_DSHS),
               funs(sum))

DSHS_metro_google = 
  merged_county %>%
  group_by(Date, Metro_Area) %>%
  summarize_at(vars(Retail_Recreation, Grocery_Pharmacy,
                    Parks, Transit,
                    Workplaces, Residential),
               funs(weighted.mean(., Population_DSHS)), na.rm = TRUE)

DSHS_metro = subset(merge(DSHS_metro_counts, DSHS_metro_pops, by = 'Metro_Area', all = TRUE), !is.na(Date))
DSHS_metro = merge(DSHS_metro, DSHS_metro_google, by = c('Date', 'Metro_Area'))
```


# STATE LEVEL

## DSHS (time series)

```{r}
state_url = 'https://www.dshs.state.tx.us/coronavirus/TexasCOVID19CaseCountData.xlsx'

download.file(state_url, destfile = 'original-sources/DSHS_state.xlsx', mode = 'wb')

# save state level file to historical database for longitudinal demo
date_out = ifelse((Sys.time() < as.POSIXct(paste0(Sys.Date(), '20:00'), tz = 'America/Chicago')),
                   Sys.Date() - 1,
                   Sys.Date())
date_out = as.Date(date_out, origin = '1970-1-1')

download.file(state_url, paste0('original-sources/historical/demo/dshs_',
                                format(date_out, '%m_%d'), '.xlsx'), mode = 'wb')

DSHS_state = read_excel_allsheets('original-sources/DSHS_state.xlsx')
```


```{r}
DSHS_tests = DSHS_state[[4]]
DSHS_tests = DSHS_tests[1:(nrow(DSHS_tests) - 3), ]

colnames(DSHS_tests) = c('Date', 'Viral_Tests', 'Antibody_Tests', 'Tests_Total', 'Positive_Rate', 'Viral_Tests_New_Avg', 'Antibody_Tests_New_Avg', 'Total_Tests_New_Avg')

# fix date (https://stackoverflow.com/questions/43230470/how-to-convert-excel-date-format-to-proper-date-in-r) 
DSHS_tests$Date = as.Date(as.integer(DSHS_tests$Date), origin = '1899-12-30')

# fix calc col type
DSHS_tests$Positive_Rate = as.numeric(DSHS_tests$Positive_Rate)
```


```{r}
# drop row num
DSHS_hospitalizations = DSHS_state[[8]][, c(2:3)]

# drop footnote
DSHS_hospitalizations = DSHS_hospitalizations[1:(nrow(DSHS_hospitalizations) - 2), ]

# fix date
DSHS_hospitalizations$Date = as.Date(DSHS_hospitalizations$Date, format = '%Y%m%d')

# set colnames
colnames(DSHS_hospitalizations)[2] = 'Hospital_Total'
```


```{r}
# merge tests & hospitalizations
DSHS_state_time = merge(DSHS_tests, DSHS_hospitalizations, by = 'Date', all = TRUE)
```

## DSHS (day counts)

```{r}
# avoids duplication of results between sheets
DSHS_state_day = data.frame(Recovered_Total = DSHS_state[[3]][1,1],
                            Active_Total = DSHS_state[[3]][1,2],
                            Tests_State_Lab = DSHS_state[[5]][1,2],
                            Tests_Commercial_Lab = DSHS_state[[5]][2,2],
                            Antibody_Tests_Positive = DSHS_state[[6]][2,2],
                            Hospital_Bed_Total = DSHS_state[[7]][2,2],
                            Hospital_Bed_Available = DSHS_state[[7]][3,2],
                            ICU_Bed_Available = DSHS_state[[7]][4,2],
                            Ventilator_Available = DSHS_state[[7]][5,2],
                            Case_Investigations = DSHS_state[[9]][[14,2]],
                            Death_Investigations = DSHS_state[[12]][14,2])
```

## DSHS Demographics

```{r}
# read in all files
current_year =  substr(Sys.Date(), 1, 4)
demo.list <- paste0('original-sources/historical/demo/',
                    list.files(path = 'original-sources/historical/demo',
                               pattern = '*.xlsx'))

DSHS_case_age <- lapply(demo.list, read_excel, sheet = 9)
DSHS_case_gender <- lapply(demo.list, read_excel, sheet = 10)
DSHS_case_race <- lapply(demo.list, read_excel, sheet = 11)
DSHS_death_age <- lapply(demo.list, read_excel, sheet = 12)
DSHS_death_gender <- lapply(demo.list, read_excel, sheet = 13)
DSHS_death_race <- lapply(demo.list, read_excel, sheet = 14)

DSHS_demo_clean = function(df, count_type) { 
  matches = str_extract_all(colnames(df)[1], '\\d*\\/\\d*')[[1]]
  date = matches[length(matches)]  # gets last instance of / (handle race/ethnicity first)
  df = df[2:(nrow(df) - 4), ]
  df[, 'Date'] = as.Date(paste0('2020/', date))
  colnames(df) = c('Group', paste0(count_type, '_Cumulative'),
                   paste0(count_type, '_PCT'), 'Date')

  # remove any rows containing total
  total_check = which(df[, 'Group'] == 'Total')
  if (length(total_check) != 0) {df = df[-which(df[, 'Group'] == 'Total'), ]}

  case_var = df[, 2]
  case_pct_var = df[, 3]
    
  # ensure values are numeric and drop coerced NAs (eg. Gender 7/8)
  df = df %>%
    mutate_at(vars(!!as.name(paste0(count_type, '_Cumulative')),
                   !!as.name(paste0(count_type, '_PCT'))),
              funs(as.numeric)) %>%
    na.omit()
  return(df)
  }

DSHS_case_age = lapply(DSHS_case_age, DSHS_demo_clean, count_type = 'Cases')
DSHS_case_gender = lapply(DSHS_case_gender, DSHS_demo_clean, count_type = 'Cases')
DSHS_case_race = lapply(DSHS_case_race, DSHS_demo_clean, count_type = 'Cases')
DSHS_death_age = lapply(DSHS_death_age, DSHS_demo_clean, count_type = 'Deaths')
DSHS_death_gender = lapply(DSHS_death_gender, DSHS_demo_clean, count_type = 'Deaths')
DSHS_death_race = lapply(DSHS_death_race, DSHS_demo_clean, count_type = 'Deaths')

# combine list of dataframes into one df
DSHS_case_age_df = data.table::rbindlist(DSHS_case_age)
DSHS_case_gender_df = data.table::rbindlist(DSHS_case_gender)
DSHS_case_race_df = data.table::rbindlist(DSHS_case_race)
DSHS_death_age_df = data.table::rbindlist(DSHS_death_age)
DSHS_death_gender_df = data.table::rbindlist(DSHS_death_gender)
DSHS_death_race_df = data.table::rbindlist(DSHS_death_race)

# combine case and death cols
DSHS_age_df = merge(DSHS_case_age_df, DSHS_death_age_df, by = c('Date', 'Group'))
DSHS_gender_df = merge(DSHS_case_gender_df, DSHS_death_gender_df, by = c('Date', 'Group'))
DSHS_race_df = merge(DSHS_case_race_df, DSHS_death_race_df, by = c('Date', 'Group'))

# fix types
DSHS_age_df[, 3:6] <- lapply(DSHS_age_df[, 3:6], as.numeric)
DSHS_gender_df[, 3:6] <- lapply(DSHS_gender_df[, 3:6], as.numeric)
DSHS_race_df[, 3:6] <- lapply(DSHS_race_df[, 3:6], as.numeric)
```

## Computed

```{r}
state_counts =
    merged_county %>%
    group_by(Date) %>%
    summarize_at(vars(Cases_Cumulative, Cases_Daily,
                      Deaths_Cumulative, Deaths_Daily,
                      Tests_Cumulative, Tests_Daily,
                      Active_Cases_Cumulative, Active_Cases_Daily),
                 funs(sum))

state_pops = 
  subset(merged_county, Date == '2020-03-04') %>%
  group_by(Date) %>%
  summarize_at(vars(Population_DSHS),
               funs(sum))

state_google = 
  merged_county %>%
  group_by(Date) %>%
  summarize_at(vars(Retail_Recreation, Grocery_Pharmacy,
                    Parks, Transit,
                    Workplaces, Residential),
               funs(weighted.mean(., Population_DSHS)), na.rm = TRUE)

state_facilities = 
  phr_df %>%
  group_by(Date) %>%
  summarize_at(vars(ALF_Total, ALF_Cases, ALF_Deaths, ALF_Recoveries,
                    Nursing_Total, Nursing_Cases, Nursing_Deaths, Nursing_Recoveries),
               funs(sum))

state_hosp_detail = 
  merged_tsa %>% 
  group_by(Date) %>%
  summarize_at(vars(Hospitalizations_Total, Hospitalizations_General, Hospitalizations_ICU,
                    Beds_Available_Total, Beds_Available_ICU, Beds_Occupied_Total, Beds_Occupied_ICU,
                    Ventilators_Available),
               funs(sum))
```


## merge

```{r}
merged_state = Reduce(function(x, y) merge(x, y, by = c('Date'), all=TRUE),
       list(state_counts, state_google, DSHS_state_time, state_facilities, state_hosp_detail))

merged_state$Population_DSHS = state_pops$Population_DSHS
```


# OUTPUT 

## City

```{r}
write.csv(merged_city, 'combined-datasets/city_pops.csv', row.names = F)
``` 

## County

```{r}
write.csv(merged_county, file = 'combined-datasets/county.csv', row.names = F)
write.csv(county_demo_2018, file = 'combined-datasets/county_demo.csv', row.names = F)
```

## TSA

```{r}
merged_tsa$TSA_Combined = paste0(merged_tsa$TSA, ' - ', merged_tsa$TSA_Name)
write.csv(merged_tsa, file = 'combined-datasets/tsa.csv', row.names = F)

hosp_tsa = merged_tsa[, c(1:3, 18:26)]
write.csv(hosp_tsa, file = 'tableau/hospitalizations_tsa.csv', row.names = F)
```

## PHR 

```{r}
write.csv(phr_df, file = 'combined-datasets/phr.csv', row.names = F)
write.csv(phr_df, file = 'tableau/phr.csv', row.names = F)
```


## Metro

```{r}
write.csv(DSHS_metro, file = 'combined-datasets/metro.csv', row.names = F)
```

## State

```{r}
library(openxlsx)
state_out = list("longitudinal" = merged_state, "current" = DSHS_state_day)
openxlsx::write.xlsx(state_out, file = "combined-datasets/state.xlsx", row.names = FALSE)
```

### Demographics

```{r}
demo_out = list("age" = DSHS_age_df, "gender" = DSHS_gender_df, "race" = DSHS_race_df)
openxlsx::write.xlsx(demo_out, file = "combined-datasets/demographics.xlsx", row.names = FALSE)
```


## TABLEAU ONLY

```{r}
tableau_county = merged_county
write.csv(tableau_county, 'tableau/county.csv', row.names = FALSE)
```


<!-- ## Long format TSA & Metro -->

<!-- ```{r} -->
<!-- # read in data -->
<!-- county = read.csv('combined-datasets/county.csv') -->
<!-- metro = read.csv('combined-datasets/metro.csv') -->
<!-- tsa = read.csv('combined-datasets/tsa.csv') -->

<!-- # combine into df -->
<!-- metro_long = merge(county, metro, by = c('Date', 'Metro_Area'), all = TRUE) -->
<!-- tsa_long = merge(county, tsa, by = c('Date', 'TSA', 'TSA_Name'), all = TRUE) -->

<!-- # drop county cols and suffixes -->
<!-- metro_long = metro_long[, -(grep('.x', colnames(metro_long), fixed = TRUE))] -->
<!-- colnames(metro_long) = gsub('.y', '', colnames(metro_long), fixed = TRUE) -->

<!-- # drop county cols and suffixes -->
<!-- tsa_long = tsa_long[, -(grep('.x', colnames(tsa_long), fixed = TRUE))] -->
<!-- colnames(tsa_long) = gsub('.y', '', colnames(tsa_long), fixed = TRUE) -->

<!-- tsa_long$TSA_Combined = paste0(tsa_long$TSA, ' - ', tsa_long$TSA_Name) -->

<!-- # output -->
<!-- # write.csv(metro_long, 'tableau/metro_long.csv', row.names = FALSE) -->
<!-- # write.csv(tsa_long, 'tableau/tsa_long.csv', row.names = FALSE) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- # transform names -->
<!-- colnames(metro)[3:length(colnames(metro))] = paste0('METRO_', colnames(metro)[3:length(colnames(metro))]) -->
<!-- colnames(tsa)[4:length(colnames(tsa))] = paste0('TSA_', colnames(tsa)[4:length(colnames(tsa))]) -->

<!-- # combine into df -->
<!-- combined_df = merge(county, metro, by = c('Date', 'Metro_Area'), all = TRUE) -->

<!-- tsa$TSA_Combined = paste0(tsa$TSA, ' - ', tsa$TSA_Name) -->

<!-- combined_df2 = merge(combined_df, tsa, by = c('Date', 'TSA', 'TSA_Name'), all = TRUE) -->

<!-- # output -->
<!-- # write.csv(combined_df2, 'tableau/combined.csv', row.names = FALSE) -->
<!-- ``` -->
